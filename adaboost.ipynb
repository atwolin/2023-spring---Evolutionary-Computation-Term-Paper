{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import copy\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import gp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold\n",
    "import deap.gp as gp\n",
    "from deap import creator, base, tools, algorithms\n",
    "from deap.gp import cxOnePoint as cx_simple\n",
    "from deap.gp import PrimitiveSet\n",
    "from data import get_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD2VEC = \"word2vec\"\n",
    "GLOVE = \"glove\"\n",
    "FASTTEXT = \"fasttext\"\n",
    "CX_RANDOM = 0\n",
    "CX_SIMPLE = 1\n",
    "CX_UNIFORM = 2\n",
    "CX_FAIR = 3\n",
    "CX_ONEPOINT = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic operators\n",
    "def protected_div(x, y):\n",
    "    mask = y == 0\n",
    "    safe_y = np.where(mask, 1, y)\n",
    "    return np.where(mask, 1, x / safe_y)\n",
    "\n",
    "\n",
    "def protected_sqrt(x):\n",
    "    sign = np.sign(x)\n",
    "    x = np.abs(x)\n",
    "    return np.sqrt(x) * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover method\n",
    "def subtree_height(tree, index):\n",
    "        \"\"\"\n",
    "        Calculate the height of the subtree starting at the given index.\n",
    "        \"\"\"\n",
    "        def height(node_index):\n",
    "            node = tree[node_index]\n",
    "            if node.arity == 0:  # Leaf node\n",
    "                return 1\n",
    "            else:\n",
    "                return 1 + max(\n",
    "                    height(child_index)\n",
    "                    for child_index in range(\n",
    "                        node_index + 1, node_index + 1 + node.arity\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return height(index)\n",
    "\n",
    "def searchSubtree_idx(tree, begin):\n",
    "        end = begin + 1\n",
    "        total = tree[begin].arity\n",
    "        while total > 0:\n",
    "            total += tree[end].arity - 1\n",
    "            end += 1\n",
    "        return begin, end\n",
    "\n",
    "def cx_uniform(ind1, ind2):\n",
    "        # No crossover on single node tree\n",
    "        if (len(ind1) < 2 or len(ind2) < 2):\n",
    "            return ind1, ind2\n",
    "\n",
    "        child = type(ind1)([])\n",
    "        parents = [ind1, ind2]\n",
    "        flag0, flag1 = 0, 0\n",
    "        left_0 = parents[0].searchSubtree(1)\n",
    "        left_1 = parents[1].searchSubtree(1)\n",
    "        b0, e0 = searchSubtree_idx(parents[0], 1)\n",
    "        b1, e1 = searchSubtree_idx(parents[1], 1)\n",
    "\n",
    "        if e0 + 1 < len(parents[0]):\n",
    "            right_0 = parents[0].searchSubtree(e0 + 1)\n",
    "            flag0 = 1\n",
    "        if e1 + 1 < len(parents[1]):\n",
    "            right_1 = parents[1].searchSubtree(e1 + 1)\n",
    "            flag1 = 1\n",
    "        left = [left_0, left_1]\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            right = [right_0, right_1]\n",
    "            r_arity = 0\n",
    "            if parents[0][e0 + 1].arity == parents[1][e1 + 1].arity:\n",
    "                r_arity = 1\n",
    "        r = random.randint(0, 1)  # root\n",
    "        m = 1 - r\n",
    "        if len(parents[r]) < len(parents[m]):\n",
    "            # root = parents[r].root\n",
    "            if flag1 == 0 or flag0 == 0:\n",
    "                return parents[r], parents[m]\n",
    "            parents[m][0] = parents[r].root\n",
    "            m = r\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            r1 = random.randint(0, 1)  # 左邊\n",
    "            if parents[r][1] == parents[r1][1]:\n",
    "                parents[r][left[r]] = parents[r1][left[r1]]\n",
    "            if r_arity == 1:\n",
    "                r2 = random.randint(0, 1)\n",
    "                parents[r][right[r]] = parents[r2][right[r2]]\n",
    "        else:\n",
    "            # print(\"只有一個子點\")\n",
    "            r1 = random.randint(0, 1)\n",
    "            parents[r][left[r1]] = parents[r1][left[r1]]\n",
    "        return parents[r], parents[r]\n",
    "\n",
    "def cx_fair(ind1, ind2):\n",
    "    \"\"\"Size fair crossover for two trees.\n",
    "    :param ind1: First tree participating in the crossover.\n",
    "    :param ind2: Second tree participating in the crossover.\n",
    "    :returns: A tuple of two trees.\n",
    "    \"\"\"\n",
    "    # No crossover on single node tree\n",
    "    if len(ind1) < 2 or len(ind2) < 2:\n",
    "        return ind1, ind2\n",
    "\n",
    "    # List all available primitive types in each individual\n",
    "    types1 = gp.defaultdict(list)\n",
    "    types2 = gp.defaultdict(list)\n",
    "    if ind1.root.ret == gp.__type__:\n",
    "        # Not STGP optimization\n",
    "        types1[gp.__type__] = list(range(1, len(ind1)))\n",
    "        types2[gp.__type__] = list(range(1, len(ind2)))\n",
    "        common_types = [gp.__type__]\n",
    "    else:\n",
    "        for idx, node in enumerate(ind1[1:], 1):\n",
    "            types1[node.ret].append(idx)\n",
    "        for idx, node in enumerate(ind2[1:], 1):\n",
    "            types2[node.ret].append(idx)\n",
    "        common_types = set(types1.keys()).intersection(set(types2.keys()))\n",
    "\n",
    "    if len(common_types) > 0:\n",
    "        type_ = random.choice(list(common_types))\n",
    "\n",
    "    index1 = random.choice(types1[type_])\n",
    "    height1 = subtree_height(ind1, index1)\n",
    "    # height = ind1.height\n",
    "\n",
    "    while True:\n",
    "        index2 = random.choice(types2[type_])\n",
    "        height2 = subtree_height(ind2, index2)\n",
    "        if height2 <= height1:\n",
    "            # print(f\"height1: {height1}, height2: {height2}\")\n",
    "            break\n",
    "    slice1 = ind1.searchSubtree(index1)\n",
    "    slice2 = ind2.searchSubtree(index2)\n",
    "    ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "    return ind1, ind2\n",
    "\n",
    "def traverse_tree(stack, res, parent, idx):\n",
    "    while res != 0:\n",
    "        res -= 1\n",
    "        idx += 1\n",
    "        stack.append((parent[idx], [], idx))\n",
    "        res += parent[idx].arity\n",
    "    # print(f\"stack: {stack}\")\n",
    "    return stack, res, idx\n",
    "\n",
    "def cx_one_point(ind1, ind2):\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    # To track the trees\n",
    "    stack1 = []\n",
    "    stack2 = []\n",
    "    # Store the common region\n",
    "    region1 = []\n",
    "    region2 = []\n",
    "\n",
    "    # Start traversing the trees\n",
    "    while idx1 < len(ind1) and idx2 < len(ind2):\n",
    "        # Push the nodes to the stack\n",
    "        stack1.append((ind1[idx1], [], idx1))\n",
    "        stack2.append((ind2[idx2], [], idx2))\n",
    "\n",
    "        # Not the same region\n",
    "        if stack1[-1][0].arity != stack2[-1][0].arity:\n",
    "            res1 = stack1[-1][0].arity\n",
    "            res2 = stack2[-1][0].arity\n",
    "            stack1, res1, idx1 = traverse_tree(stack1, res1, ind1, idx1)\n",
    "            stack2, res2, idx2 = traverse_tree(stack2, res2, ind2, idx2)\n",
    "        else:\n",
    "            region1.append([ind1[idx1], idx1])\n",
    "            region2.append([ind2[idx2], idx2])\n",
    "\n",
    "        idx1 += 1\n",
    "        idx2 += 1\n",
    "\n",
    "    # for pri, idx in region1:\n",
    "    #     print(f\"{idx}: {pri.name}\")\n",
    "\n",
    "    # Select crossover point\n",
    "    if len(region1) > 0:\n",
    "        point = random.randint(0, len(region1) - 1)\n",
    "        # print(f\"crossover point: {point}\")\n",
    "        # print(f\"crossover point for trees: {region1[point]}, {region2[point]}\")\n",
    "\n",
    "    # Swap subtrees\n",
    "    if len(region1) > 0:\n",
    "        slice1 = ind1.searchSubtree(region1[point][1])\n",
    "        slice2 = ind2.searchSubtree(region2[point][1])\n",
    "        ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    def __init__(self, embeddings, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset):\n",
    "        self.embeddings = embeddings\n",
    "        self.dim = dimension\n",
    "        self.pop_size = population_size\n",
    "        self.pop = None\n",
    "        self.cx_method = crossover_method\n",
    "        self.cx_pb = cross_prob\n",
    "        self.mut_pb = mut_prob\n",
    "        self.num_gen = num_generations\n",
    "        self.inputword = dataset[0].str.split().apply(lambda x: x[:5])\n",
    "        self.realword = dataset[0].str.split().str.get(5)\n",
    "        self.eval_count = 0\n",
    "\n",
    "    def register(self):\n",
    "        # Function set\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5)\n",
    "        self.pset.addPrimitive(np.add, 2)\n",
    "        self.pset.addPrimitive(np.subtract, 2)\n",
    "        self.pset.addPrimitive(np.multiply, 2)\n",
    "        self.pset.addPrimitive(protected_div, 2)\n",
    "        self.pset.addPrimitive(protected_sqrt, 1)\n",
    "        self.pset.addPrimitive(np.square, 1)\n",
    "        # Terminal set\n",
    "        count = 0\n",
    "        self.pset.renameArguments(ARG0=\"a\", ARG1=\"b\", ARG2=\"c\", ARG3=\"d\", ARG4=\"e\")\n",
    "        # for line in self.inputword:\n",
    "            # for word in line:\n",
    "                # if count < 5:\n",
    "                    # print(f\"conut: {count}\")\n",
    "                    # print(f\"embedding: {embeddings[word]}, {type(embeddings[word])}\")\n",
    "                    # count += 1\n",
    "                # self.pset.addTerminal(word)\n",
    "\n",
    "        # Initialize the individual\n",
    "        if \"Individual\" not in creator.__dict__:\n",
    "            creator.create(\"FitnessMax\", base.Fitness, weights=(1,))\n",
    "            creator.create(\n",
    "                \"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax, pset=self.pset\n",
    "            )\n",
    "\n",
    "        # Initialize the toolbox\n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=1, max_=5)\n",
    "        self.toolbox.register(\n",
    "            \"individual\", tools.initIterate, creator.Individual, self.toolbox.expr\n",
    "        )\n",
    "        self.toolbox.register(\n",
    "            \"population\",\n",
    "            tools.initRepeat,\n",
    "            list,\n",
    "            self.toolbox.individual,\n",
    "            n=self.pop_size,\n",
    "        )\n",
    "\n",
    "        # Register the operators\n",
    "        # self.toolbox.register(\"select_candidate\", tools.selRandom, tournsize=3)\n",
    "        self.toolbox.register(\"crossover\", self.crossover)\n",
    "        self.toolbox.register(\n",
    "            \"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset\n",
    "        )\n",
    "        self.toolbox.decorate(\n",
    "            \"mutate\", gp.staticLimit(operator.attrgetter(\"height\"), max_value=5)\n",
    "        )\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "\n",
    "        # Register the record for analyzing\n",
    "        self.stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "        self.stats.register(\"avg\", np.mean)\n",
    "        self.stats.register(\"std\", np.std)\n",
    "        self.stats.register(\"min\", np.min)\n",
    "        self.stats.register(\"max\", np.max)\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        data = np.where(np.isinf(data), np.finfo(np.float32).max, data)\n",
    "        data = np.nan_to_num(data, nan=0.0)\n",
    "        return data\n",
    "\n",
    "    def evaluate(self, individual, input_word):\n",
    "        \"\"\"Evalute the fitness of an individual\"\"\"\n",
    "        # print(f\"individual種類:{type(individual)}\")\n",
    "        func = gp.compile(individual, self.pset)\n",
    "        total_similarity = 0.0\n",
    "        for data_index in range(len(input_word)):\n",
    "            words = self.inputword.iloc[data_index]\n",
    "            in_vectors = [self.embeddings[word] for word in words]\n",
    "            a, b, c, d, e = in_vectors[:5]\n",
    "\n",
    "            y = self.realword.iloc[data_index]\n",
    "            out_vector = self.embeddings[y]\n",
    "\n",
    "            predict = self.clean_data(func(a, b, c, d, e))\n",
    "            similarity = cosine_similarity([predict], [out_vector])[0][0]\n",
    "            total_similarity += similarity\n",
    "\n",
    "        fitness = total_similarity / len(self.inputword)\n",
    "        ftiness = self.clean_data(fitness)\n",
    "        self.eval_count += 1\n",
    "        return (fitness,)\n",
    "\n",
    "    def crossover(self, ind1, ind2):\n",
    "        parents = [ind1, ind2]\n",
    "        if random.uniform(0, 1) < self.cx_pb:\n",
    "            if self.cx_method == CX_RANDOM:\n",
    "                choice = random.randint(1, 4)\n",
    "            if choice == CX_SIMPLE or self.cx_method == CX_SIMPLE:\n",
    "                ind1, ind2 = cx_simple(ind1, ind2)\n",
    "            elif choice == CX_UNIFORM or self.cx_method == CX_UNIFORM:\n",
    "                ind1, ind2 = cx_uniform(ind1, ind2)\n",
    "            elif choice == CX_ONEPOINT or self.cx_method == CX_FAIR:\n",
    "                ind1, ind2 = cx_fair(ind1, ind2)\n",
    "            else:  # self.cx_method == 4:\n",
    "                ind1, ind2 = cx_one_point(ind1, ind2)\n",
    "        # return ind1, ind2\n",
    "\n",
    "        fitness_ind1 = self.toolbox.evaluate(ind1, self.realword)\n",
    "        # ?:\n",
    "        # if self.cx_method == 2:\n",
    "        #     parents.remove(b)\n",
    "        #     return parents\n",
    "        fitness_ind2 = self.toolbox.evaluate(ind2, self.realword)\n",
    "        if fitness_ind1 <= fitness_ind2:\n",
    "            parents.remove(ind1)\n",
    "            return parents\n",
    "        else:\n",
    "            parents.remove(ind2)\n",
    "            return parents\n",
    "\n",
    "    def mutate(self, offspring):\n",
    "        if random.uniform(0, 1) < self.mut_pb:\n",
    "            self.toolbox.mutate(offspring[0])\n",
    "            offspring[0].fitness.values = self.toolbox.evaluate(offspring[0], self.realword)\n",
    "        return offspring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# Boosting parameters\n",
    "boosting_interval = 5\n",
    "\n",
    "population_size = 50\n",
    "dim = 10\n",
    "crossover_method = CX_RANDOM\n",
    "cross_prob = 0.5\n",
    "mut_prob = 0.1\n",
    "num_generations = 30\n",
    "embedding = WORD2VEC\n",
    "\n",
    "dataset, embeddings, word2vec_model = get_embeddings(WORD2VEC, 10, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53497</th>\n",
       "      <td>greens push for district allowance boost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203369</th>\n",
       "      <td>overnight rain causes flooding in wandoan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140334</th>\n",
       "      <td>chamber pleads for more gayndah police</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37092</th>\n",
       "      <td>three gorges project raises dam questions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228309</th>\n",
       "      <td>water levels slowly fall at quambatook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0\n",
       "53497    greens push for district allowance boost\n",
       "203369  overnight rain causes flooding in wandoan\n",
       "140334     chamber pleads for more gayndah police\n",
       "37092   three gorges project raises dam questions\n",
       "228309     water levels slowly fall at quambatook"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the population\n",
    "trees = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset)\n",
    "trees.register()\n",
    "\n",
    "trees.pop = trees.toolbox.population(n = trees.pop_size)\n",
    "# Evaluate the entire population\n",
    "fitnesses = map(trees.toolbox.evaluate, trees.pop, trees.inputword)\n",
    "for ind, fit in zip(trees.pop, fitnesses):\n",
    "    ind.fitness.values = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize instance weights\n",
    "dataset[\"weights\"] = 1.0 / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53497</th>\n",
       "      <td>greens push for district allowance boost</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203369</th>\n",
       "      <td>overnight rain causes flooding in wandoan</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140334</th>\n",
       "      <td>chamber pleads for more gayndah police</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37092</th>\n",
       "      <td>three gorges project raises dam questions</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228309</th>\n",
       "      <td>water levels slowly fall at quambatook</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0   weights\n",
       "53497    greens push for district allowance boost  0.000375\n",
       "203369  overnight rain causes flooding in wandoan  0.000375\n",
       "140334     chamber pleads for more gayndah police  0.000375\n",
       "37092   three gorges project raises dam questions  0.000375\n",
       "228309     water levels slowly fall at quambatook  0.000375"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
