{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import numpy as np\n",
    "# import gp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import deap.gp as gp\n",
    "from deap import creator, base, tools, algorithms\n",
    "from deap.gp import cxOnePoint as cx_simple\n",
    "from deap.gp import PrimitiveSet\n",
    "from data import load_model, get_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "WORD2VEC = \"word2vec\"\n",
    "GLOVE = \"glove\"\n",
    "FASTTEXT = \"fasttext\"\n",
    "\n",
    "pop_size = s = 50\n",
    "m = 5\n",
    "dim = 10\n",
    "cx_method = CX_RANDOM\n",
    "mut_pb = 0.1\n",
    "n_gen = 30\n",
    "word2vec_model, glove_model, fastText_model = load_model(dim)\n",
    "data, embeddings = get_embeddings(WORD2VEC, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic operators\n",
    "def protected_div(x, y):\n",
    "    mask = y == 0\n",
    "    safe_y = np.where(mask, 1, y)\n",
    "    return np.where(mask, 1, x / safe_y)\n",
    "\n",
    "\n",
    "def protected_sqrt(x):\n",
    "    sign = np.sign(x)\n",
    "    x = np.abs(x)\n",
    "    return np.sqrt(x) * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover method\n",
    "CX_RANDOM = 0\n",
    "CX_SIMPLE = 1\n",
    "CX_UNIFORM = 2\n",
    "CX_FAIR = 3\n",
    "CX_ONEPOINT = 4\n",
    "def subtree_height(self, tree, index):\n",
    "        \"\"\"\n",
    "        Calculate the height of the subtree starting at the given index.\n",
    "        \"\"\"\n",
    "        def height(node_index):\n",
    "            node = tree[node_index]\n",
    "            if node.arity == 0:  # Leaf node\n",
    "                return 1\n",
    "            else:\n",
    "                return 1 + max(\n",
    "                    height(child_index)\n",
    "                    for child_index in range(\n",
    "                        node_index + 1, node_index + 1 + node.arity\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return height(index)\n",
    "\n",
    "def searchSubtree_idx(self, tree, begin):\n",
    "        end = begin + 1\n",
    "        total = tree[begin].arity\n",
    "        while total > 0:\n",
    "            total += tree[end].arity - 1\n",
    "            end += 1\n",
    "        return begin, end\n",
    "\n",
    "def cx_uniform(self, ind1, ind2):\n",
    "        # No crossover on single node tree\n",
    "        if (len(ind1) < 2 or len(ind2) < 2):\n",
    "            return ind1, ind2\n",
    "\n",
    "        child = type(ind1)([])\n",
    "        parents = [ind1, ind2]\n",
    "        flag0, flag1 = 0, 0\n",
    "        left_0 = parents[0].searchSubtree(1)\n",
    "        left_1 = parents[1].searchSubtree(1)\n",
    "        b0, e0 = self.searchSubtree_idx(parents[0], 1)\n",
    "        b1, e1 = self.searchSubtree_idx(parents[1], 1)\n",
    "\n",
    "        if e0 + 1 < len(parents[0]):\n",
    "            right_0 = parents[0].searchSubtree(e0 + 1)\n",
    "            flag0 = 1\n",
    "        if e1 + 1 < len(parents[1]):\n",
    "            right_1 = parents[1].searchSubtree(e1 + 1)\n",
    "            flag1 = 1\n",
    "        left = [left_0, left_1]\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            right = [right_0, right_1]\n",
    "            r_arity = 0\n",
    "            if parents[0][e0 + 1].arity == parents[1][e1 + 1].arity:\n",
    "                r_arity = 1\n",
    "        r = random.randint(0, 1)  # root\n",
    "        m = 1 - r\n",
    "        if len(parents[r]) < len(parents[m]):\n",
    "            # root = parents[r].root\n",
    "            if flag1 == 0 or flag0 == 0:\n",
    "                return parents[r], parents[m]\n",
    "            parents[m][0] = parents[r].root\n",
    "            m = r\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            r1 = random.randint(0, 1)  # 左邊\n",
    "            if parents[r][1] == parents[r1][1]:\n",
    "                parents[r][left[r]] = parents[r1][left[r1]]\n",
    "            if r_arity == 1:\n",
    "                r2 = random.randint(0, 1)\n",
    "                parents[r][right[r]] = parents[r2][right[r2]]\n",
    "        else:\n",
    "            # print(\"只有一個子點\")\n",
    "            r1 = random.randint(0, 1)\n",
    "            parents[r][left[r1]] = parents[r1][left[r1]]\n",
    "        return parents[r], parents[r]\n",
    "\n",
    "    def cx_fair(self, ind1, ind2):\n",
    "        \"\"\"Size fair crossover for two trees.\n",
    "        :param ind1: First tree participating in the crossover.\n",
    "        :param ind2: Second tree participating in the crossover.\n",
    "        :returns: A tuple of two trees.\n",
    "        \"\"\"\n",
    "        # No crossover on single node tree\n",
    "        if len(ind1) < 2 or len(ind2) < 2:\n",
    "            return ind1, ind2\n",
    "\n",
    "        # List all available primitive types in each individual\n",
    "        types1 = gp.defaultdict(list)\n",
    "        types2 = gp.defaultdict(list)\n",
    "        if ind1.root.ret == gp.__type__:\n",
    "            # Not STGP optimization\n",
    "            types1[gp.__type__] = list(range(1, len(ind1)))\n",
    "            types2[gp.__type__] = list(range(1, len(ind2)))\n",
    "            common_types = [gp.__type__]\n",
    "        else:\n",
    "            for idx, node in enumerate(ind1[1:], 1):\n",
    "                types1[node.ret].append(idx)\n",
    "            for idx, node in enumerate(ind2[1:], 1):\n",
    "                types2[node.ret].append(idx)\n",
    "            common_types = set(types1.keys()).intersection(set(types2.keys()))\n",
    "\n",
    "        if len(common_types) > 0:\n",
    "            type_ = random.choice(list(common_types))\n",
    "\n",
    "        index1 = random.choice(types1[type_])\n",
    "        height1 = self.subtree_height(ind1, index1)\n",
    "        # height = ind1.height\n",
    "\n",
    "        while True:\n",
    "            index2 = random.choice(types2[type_])\n",
    "            height2 = self.subtree_height(ind2, index2)\n",
    "            if height2 <= height1:\n",
    "                # print(f\"height1: {height1}, height2: {height2}\")\n",
    "                break\n",
    "        slice1 = ind1.searchSubtree(index1)\n",
    "        slice2 = ind2.searchSubtree(index2)\n",
    "        ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "        return ind1, ind2\n",
    "\n",
    "    def traverse_tree(self, stack, res, parent, idx):\n",
    "        while res != 0:\n",
    "            res -= 1\n",
    "            idx += 1\n",
    "            stack.append((parent[idx], [], idx))\n",
    "            res += parent[idx].arity\n",
    "        # print(f\"stack: {stack}\")\n",
    "        return stack, res, idx\n",
    "\n",
    "    def cx_one_point(self, ind1, ind2):\n",
    "        idx1 = 0\n",
    "        idx2 = 0\n",
    "        # To track the trees\n",
    "        stack1 = []\n",
    "        stack2 = []\n",
    "        # Store the common region\n",
    "        region1 = []\n",
    "        region2 = []\n",
    "\n",
    "        # Start traversing the trees\n",
    "        while idx1 < len(ind1) and idx2 < len(ind2):\n",
    "            # Push the nodes to the stack\n",
    "            stack1.append((ind1[idx1], [], idx1))\n",
    "            stack2.append((ind2[idx2], [], idx2))\n",
    "\n",
    "            # Not the same region\n",
    "            if stack1[-1][0].arity != stack2[-1][0].arity:\n",
    "                res1 = stack1[-1][0].arity\n",
    "                res2 = stack2[-1][0].arity\n",
    "                stack1, res1, idx1 = self.traverse_tree(stack1, res1, ind1, idx1)\n",
    "                stack2, res2, idx2 = self.traverse_tree(stack2, res2, ind2, idx2)\n",
    "            else:\n",
    "                region1.append([ind1[idx1], idx1])\n",
    "                region2.append([ind2[idx2], idx2])\n",
    "\n",
    "            idx1 += 1\n",
    "            idx2 += 1\n",
    "\n",
    "        # for pri, idx in region1:\n",
    "        #     print(f\"{idx}: {pri.name}\")\n",
    "\n",
    "        # Select crossover point\n",
    "        if len(region1) > 0:\n",
    "            point = random.randint(0, len(region1) - 1)\n",
    "            # print(f\"crossover point: {point}\")\n",
    "            # print(f\"crossover point for trees: {region1[point]}, {region2[point]}\")\n",
    "\n",
    "        # Swap subtrees\n",
    "        if len(region1) > 0:\n",
    "            slice1 = ind1.searchSubtree(region1[point][1])\n",
    "            slice2 = ind2.searchSubtree(region2[point][1])\n",
    "            ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "\n",
    "        # Select the one has higher fitness value\n",
    "        ### TODO ###\n",
    "\n",
    "        return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    def __init__(self, embedding, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations):\n",
    "        self.embedding = embeddings\n",
    "        self.dim = dimension\n",
    "        self.pop_size = population_size\n",
    "        self.cx_method = crossover_method\n",
    "        self.cx_prob = cross_prob\n",
    "        self.mut_prob = mut_prob\n",
    "        self.num_gen = num_generations\n",
    "        self.fitness = self.evaluate_population()\n",
    "        self.eval_count = 0\n",
    "\n",
    "    def register(self):\n",
    "        # Function set\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5)\n",
    "        self.pset.addPrimitive(np.add, 2)\n",
    "        self.pset.addPrimitive(np.subtract, 2)\n",
    "        self.pset.addPrimitive(np.multiply, 2)\n",
    "        self.pset.addPrimitive(protected_div, 2)\n",
    "        self.pset.addPrimitive(protected_sqrt, 1)\n",
    "        self.pset.addPrimitive(np.square, 1)\n",
    "        # Terminal set\n",
    "        self.pset.renameArguments(ARG0=\"a\", ARG1=\"b\", ARG2=\"c\", ARG3=\"d\", ARG4=\"e\")\n",
    "\n",
    "        # Initialize the individual\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1,))\n",
    "        creator.create(\n",
    "            \"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax, pset=self.pset\n",
    "        )\n",
    "\n",
    "        # Initialize the toolbox\n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=1, max_=5)\n",
    "        self.toolbox.register(\n",
    "            \"individual\", tools.initIterate, creator.Individual, self.toolbox.expr\n",
    "        )\n",
    "        elf.toolbox.register(\n",
    "            \"population\",\n",
    "            tools.initRepeat,\n",
    "            list,\n",
    "            self.toolbox.individual,\n",
    "            n=self.pop_size,\n",
    "        )\n",
    "\n",
    "        # Register the operators\n",
    "        self.toolbox.register(\"select_candidate\", tools.selRandom, tournsize=3)\n",
    "        self.toolbox.register(\"crossover\", self.crossover)\n",
    "        self.toolbox.register(\"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset)\n",
    "        self.toolbox.register(\"mutate\", gp.staticLimit(operator.attrgetter(\"height\"), max_value=5))\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "\n",
    "        # Register the record for analyzing\n",
    "        self.stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "        self.stats.register(\"avg\", np.mean)\n",
    "        self.stats.register(\"std\", np.std)\n",
    "        self.stats.register(\"min\", np.min)\n",
    "        self.stats.register(\"max\", np.max)\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        data = np.where(np.isinf(data), np.finfo(np.float32).max, data)\n",
    "        data = np.nan_to_num(data, nan=0.0)\n",
    "        return data\n",
    "\n",
    "    def evaluate(self, individual, input_word):\n",
    "        \"\"\"Evalute the fitness of an individual\"\"\"\n",
    "        # print(f\"individual種類:{type(individual)}\")\n",
    "        func = gp.compile(individual, self.pset)\n",
    "        total_similarity = 0.0\n",
    "        for data_index in range(len(input_word)):\n",
    "            words = self.inputword.iloc[data_index]\n",
    "            in_vectors = [self.embeddings[word] for word in words]\n",
    "            a, b, c, d, e = in_vectors[:5]\n",
    "\n",
    "            y = self.realword.iloc[data_index]\n",
    "            out_vector = self.embeddings[y]\n",
    "\n",
    "            predict = self.clean_data(func(a, b, c, d, e))\n",
    "            similarity = cosine_similarity([predict], [out_vector])[0][0]\n",
    "            total_similarity += similarity\n",
    "\n",
    "        fitness = total_similarity / len(self.inputword)\n",
    "        ftiness = self.clean_data(fitness)\n",
    "        self.eval_count += 1\n",
    "        return (fitness,)\n",
    "\n",
    "    def crossover(self, ind1, ind2):\n",
    "        if random.uniform(0, 1) < self.cx_prob:\n",
    "            if self.cx_method == CX_RANDOM:\n",
    "                choice = random.randint(0, 4)\n",
    "            if self.cx_method == CX_SIMPLE:\n",
    "                ind1, ind2 = cx_simple(parent1, parent2)\n",
    "            elif self.cx_method == CX_UNIFORM:\n",
    "                ind1, ind2 = cx_uniform(parent1, parent2)\n",
    "            elif self.cx_method == 3:\n",
    "                ind1, ind2 = self.toolbox.cx_fair(parent1, parent2)\n",
    "            else:  # self.cx_method == 4:\n",
    "                ind1, ind2 = self.toolbox.cx_one(parent1, parent2)\n",
    "\n",
    "        fitness_ind1 = self.toolbox.evaluate(ind1)\n",
    "        # ?:\n",
    "        # if self.cx_method == 2:\n",
    "        #     parents.remove(b)\n",
    "        #     return parents\n",
    "        fitness_ind2 = self.toolbox.evaluate(ind2)\n",
    "        if fitness_ind1 <= fitness_ind2:\n",
    "            return ind1\n",
    "        else:\n",
    "            return ind2\n",
    "        return\n",
    "\n",
    "    def mutate(self, offspring):\n",
    "        if random.uniform(0, 1) < self.mut_prob:\n",
    "            self.toolbox.mutate(child[0])\n",
    "            del child[0].fitness.values\n",
    "        return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_gp = GP(embedding, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "\n",
    "def initialize_pop(self):\n",
    "        self.register()\n",
    "        # print(self.pop_size)\n",
    "        self.pop = self.toolbox.population(n=self.pop_size)\n",
    "        # for ind in self.pop:\n",
    "        #    print(str(ind))\n",
    "        # Evaluate the entire population\n",
    "        fitnesses = map(self.toolbox.evaluate, self.pop)\n",
    "        for ind, fit in zip(self.pop, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        # print(f\"selfpop種類:{type(self.pop[0])}\")\n",
    "\n",
    "def select_p(self):\n",
    "        candidates =\n",
    "\n",
    "def select_s(self, parents, child):\n",
    "        # print(f\"父母：{parents}\")\n",
    "        # print(f\"子代：{child}\")\n",
    "        c_f = self.toolbox.evaluate(child[0])\n",
    "        # c_f = child.fitness.valuesx\n",
    "        p0_f = parents[0].fitness.values\n",
    "        p1_f = parents[1].fitness.values\n",
    "        # print(f\"三選一：{c_f},{p0_f},{p1_f}\")\n",
    "        if c_f <= p0_f and c_f <= p1_f:\n",
    "            return\n",
    "        else:\n",
    "            if min(p0_f, p1_f) == p0_f:\n",
    "                idx = self.pop.index(parents[0])\n",
    "                self.pop[idx] = child[0]\n",
    "                # self.pop[idx].fitness.value = self.toolbox.evaluate(child[0])\n",
    "                # child[0].fitness.value = temp[0]\n",
    "                # parents[0]=child[0]\n",
    "            else:\n",
    "                idx = self.pop.index(parents[1])\n",
    "                self.pop[idx] = child[0]\n",
    "                # child[0].fitness.value = self.toolbox.evaluate(child[0])\n",
    "                # child[0].fitness.value = temp[0]\n",
    "                # parents[1]=child[0]\n",
    "        print(f\"有用篩選\")\n",
    "        self.pop[idx].fitness.value = self.toolbox.evaluate(child[0])\n",
    "        # print(f\"有用篩遠後的適應增加 {self.pop[idx].fitness.value}\")\n",
    "        return None\n",
    "\n",
    "def evolving(self):\n",
    "        # for g in range(self.n_gen):\n",
    "        print(\"開始進化！\")\n",
    "        while self.eval_count < 1000:\n",
    "            parents, childs = self.select_p()\n",
    "            # print(f\"parents適應度: {parents[0].fitness.values},{parents[1].fitness.values}\")\n",
    "            # print(f\"父母類型： {type(parents)} 小孩類型：{type(childs)}\")\n",
    "            child = self.crossover(childs)\n",
    "            # print(f\"交叉完成type！: {type(child)}\")\n",
    "            child = self.mutate(child)\n",
    "            # print(f\"突變完成type！: {type(child)}\")\n",
    "            self.select_s(parents, child)\n",
    "            # self.pop.append()\n",
    "            if self.eval_count % 10 == 0:\n",
    "                print(f\"ＥＶＡＬ次數：{self.eval_count}\")\n",
    "                # print(f\"族群 {len(self.pop)}和shape{self.pop.shape}\")\n",
    "                record = self.stats.compile(self.pop)\n",
    "                print(record)\n",
    "            # print(f\"ＥＶＡＬ次數：{self.eval_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m num_archive \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Set up the 3 types of GP trees\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m word2vec_setup \u001b[38;5;241m=\u001b[39m \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcx_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmut_pb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWORD2VEC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m word2vec_setup\u001b[38;5;241m.\u001b[39mregister()\n\u001b[1;32m      9\u001b[0m glove_setup \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mGP(m, dim, cx_method, mut_pb, n_gen, data, GLOVE)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "# Record all individuals\n",
    "inds = np.zeros((s, dim))\n",
    "# Number of archive (forest size)\n",
    "num_archive = 10\n",
    "\n",
    "# Set up the 3 types of GP trees\n",
    "word2vec_setup = gp.GP(embeddings, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "word2vec_setup.register()\n",
    "glove_setup = gp.GP(m, dim, cx_method, mut_pb, n_gen, data, GLOVE)\n",
    "glove_setup.register()\n",
    "fasttext_setup = gp.GP(m, dim, cx_method, mut_pb, n_gen, data, FASTTEXT)\n",
    "fasttext_setup.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Randomly initialize the population, 1/3 for each embedding\n",
    "for i in range(s):\n",
    "    if i % 3 == 0:\n",
    "\n",
    "    elif i % 3 == 1:\n",
    "\n",
    "    else:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each generation (n_gen generations)\n",
    "    # For each individual (DT) (s individuals)\n",
    "        # For each GP tree (m trees)\n",
    "            # Randomly initialize the tree\n",
    "\n",
    "        # For each individual (DT)\n",
    "            # Randomly select another individual\n",
    "            # Randomly select a tree from each individual\n",
    "            # Crossover the two trees\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "            # Mutation\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "        # Evaluate the fitness of each individual: Fivefold cross-validation\n",
    "        # Traing dataset: divided into five folds\n",
    "        # For four folds: train the a DT model\n",
    "        # For the remaining fold: test the model\n",
    "        # Concatenate these five loss values into a fitness vector\n",
    "\n",
    "        # Select the best individual: Automatic lexicase selection\n",
    "        # Fitness vector L: i-th individual's fitness vector\n",
    "        # While the number of selected individuals == s\n",
    "            # Randomly choose an index j\n",
    "                # j = np.random.randint(m)\n",
    "            # Threshold theta = min(L_i[j]) + median(abs(L_i[j] + median(L_k[j]))\n",
    "                # Calculate the median absolute deviation (MAD)\n",
    "                    # fitness_j = [L[j] for L in individauls]\n",
    "                    # median_j = np.median(fitness_j)\n",
    "                    # mad_j = np.median([abs(f - median_j) for f in fitness_j])\n",
    "                # Calculate the threshold theta\n",
    "                    # theta_j = np.min(fitness_j) + mad_j\n",
    "            # For each individual\n",
    "                # j-th fitness element > theta -> preserve the individual\n",
    "                # Number of selected individuals\n",
    "                # Case 1: > 1, then repeat the filtering process\n",
    "                # Case 2: == 1, then select the individual\n",
    "                # Case 3: == 0, then randomly select an individual\n",
    "\n",
    "        # Archive the best individual\n",
    "        # For each selected individual\n",
    "            # If the number of selected individuals < remain num_archive\n",
    "                # Add to the archive\n",
    "            # Else, replace the worst individual in the archive with the best individual\n",
    "                # Find the minimum fitness value; fitness value = average of the fitness vector\n",
    "    # Return the archive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
