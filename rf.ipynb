{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import copy\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import gp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import deap.gp as gp\n",
    "from deap import creator, base, tools, algorithms\n",
    "from deap.gp import cxOnePoint as cx_simple\n",
    "from deap.gp import PrimitiveSet\n",
    "from data import load_model, get_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "WORD2VEC = \"word2vec\"\n",
    "GLOVE = \"glove\"\n",
    "FASTTEXT = \"fasttext\"\n",
    "CX_RANDOM = 0\n",
    "CX_SIMPLE = 1\n",
    "CX_UNIFORM = 2\n",
    "CX_FAIR = 3\n",
    "CX_ONEPOINT = 4\n",
    "\n",
    "population_size = s = 50\n",
    "m = 5\n",
    "dim = 10\n",
    "crossover_method = CX_RANDOM\n",
    "cross_prob = 0.5\n",
    "mut_prob = 0.1\n",
    "num_generations = 30\n",
    "embedding = WORD2VEC\n",
    "\n",
    "word2vec_model, glove_model, fastText_model = load_model(dim)\n",
    "dataset, embeddings = get_embeddings(WORD2VEC, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2669"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136041         [fair, trade, code, for, indigenous]\n",
       "231043           [car, crash, victim, succumbs, to]\n",
       "218841          [eu, calls, for, georgia, conflict]\n",
       "118981              [r, sivarasa, speaks, to, asia]\n",
       "259801     [truck, driver, critical, after, bridge]\n",
       "                            ...                    \n",
       "8861      [racv, fights, for, highway, duplication]\n",
       "23882                 [china, hong, kong, on, sars]\n",
       "24096        [debt, stricken, school, placed, into]\n",
       "228666          [tourism, boss, defends, cash, for]\n",
       "97156          [more, bathurst, school, sex, abuse]\n",
       "Name: 0, Length: 2669, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = dataset[0].str.split(\" \").apply(lambda x: x[:5])\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic operators\n",
    "def protected_div(x, y):\n",
    "    mask = y == 0\n",
    "    safe_y = np.where(mask, 1, y)\n",
    "    return np.where(mask, 1, x / safe_y)\n",
    "\n",
    "\n",
    "def protected_sqrt(x):\n",
    "    sign = np.sign(x)\n",
    "    x = np.abs(x)\n",
    "    return np.sqrt(x) * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover method\n",
    "def subtree_height(tree, index):\n",
    "        \"\"\"\n",
    "        Calculate the height of the subtree starting at the given index.\n",
    "        \"\"\"\n",
    "        def height(node_index):\n",
    "            node = tree[node_index]\n",
    "            if node.arity == 0:  # Leaf node\n",
    "                return 1\n",
    "            else:\n",
    "                return 1 + max(\n",
    "                    height(child_index)\n",
    "                    for child_index in range(\n",
    "                        node_index + 1, node_index + 1 + node.arity\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return height(index)\n",
    "\n",
    "def searchSubtree_idx(tree, begin):\n",
    "        end = begin + 1\n",
    "        total = tree[begin].arity\n",
    "        while total > 0:\n",
    "            total += tree[end].arity - 1\n",
    "            end += 1\n",
    "        return begin, end\n",
    "\n",
    "def cx_uniform(ind1, ind2):\n",
    "        # No crossover on single node tree\n",
    "        if (len(ind1) < 2 or len(ind2) < 2):\n",
    "            return ind1, ind2\n",
    "\n",
    "        child = type(ind1)([])\n",
    "        parents = [ind1, ind2]\n",
    "        flag0, flag1 = 0, 0\n",
    "        left_0 = parents[0].searchSubtree(1)\n",
    "        left_1 = parents[1].searchSubtree(1)\n",
    "        b0, e0 = searchSubtree_idx(parents[0], 1)\n",
    "        b1, e1 = searchSubtree_idx(parents[1], 1)\n",
    "\n",
    "        if e0 + 1 < len(parents[0]):\n",
    "            right_0 = parents[0].searchSubtree(e0 + 1)\n",
    "            flag0 = 1\n",
    "        if e1 + 1 < len(parents[1]):\n",
    "            right_1 = parents[1].searchSubtree(e1 + 1)\n",
    "            flag1 = 1\n",
    "        left = [left_0, left_1]\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            right = [right_0, right_1]\n",
    "            r_arity = 0\n",
    "            if parents[0][e0 + 1].arity == parents[1][e1 + 1].arity:\n",
    "                r_arity = 1\n",
    "        r = random.randint(0, 1)  # root\n",
    "        m = 1 - r\n",
    "        if len(parents[r]) < len(parents[m]):\n",
    "            # root = parents[r].root\n",
    "            if flag1 == 0 or flag0 == 0:\n",
    "                return parents[r], parents[m]\n",
    "            parents[m][0] = parents[r].root\n",
    "            m = r\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            r1 = random.randint(0, 1)  # 左邊\n",
    "            if parents[r][1] == parents[r1][1]:\n",
    "                parents[r][left[r]] = parents[r1][left[r1]]\n",
    "            if r_arity == 1:\n",
    "                r2 = random.randint(0, 1)\n",
    "                parents[r][right[r]] = parents[r2][right[r2]]\n",
    "        else:\n",
    "            # print(\"只有一個子點\")\n",
    "            r1 = random.randint(0, 1)\n",
    "            parents[r][left[r1]] = parents[r1][left[r1]]\n",
    "        return parents[r], parents[r]\n",
    "\n",
    "def cx_fair(ind1, ind2):\n",
    "    \"\"\"Size fair crossover for two trees.\n",
    "    :param ind1: First tree participating in the crossover.\n",
    "    :param ind2: Second tree participating in the crossover.\n",
    "    :returns: A tuple of two trees.\n",
    "    \"\"\"\n",
    "    # No crossover on single node tree\n",
    "    if len(ind1) < 2 or len(ind2) < 2:\n",
    "        return ind1, ind2\n",
    "\n",
    "    # List all available primitive types in each individual\n",
    "    types1 = gp.defaultdict(list)\n",
    "    types2 = gp.defaultdict(list)\n",
    "    if ind1.root.ret == gp.__type__:\n",
    "        # Not STGP optimization\n",
    "        types1[gp.__type__] = list(range(1, len(ind1)))\n",
    "        types2[gp.__type__] = list(range(1, len(ind2)))\n",
    "        common_types = [gp.__type__]\n",
    "    else:\n",
    "        for idx, node in enumerate(ind1[1:], 1):\n",
    "            types1[node.ret].append(idx)\n",
    "        for idx, node in enumerate(ind2[1:], 1):\n",
    "            types2[node.ret].append(idx)\n",
    "        common_types = set(types1.keys()).intersection(set(types2.keys()))\n",
    "\n",
    "    if len(common_types) > 0:\n",
    "        type_ = random.choice(list(common_types))\n",
    "\n",
    "    index1 = random.choice(types1[type_])\n",
    "    height1 = subtree_height(ind1, index1)\n",
    "    # height = ind1.height\n",
    "\n",
    "    while True:\n",
    "        index2 = random.choice(types2[type_])\n",
    "        height2 = subtree_height(ind2, index2)\n",
    "        if height2 <= height1:\n",
    "            # print(f\"height1: {height1}, height2: {height2}\")\n",
    "            break\n",
    "    slice1 = ind1.searchSubtree(index1)\n",
    "    slice2 = ind2.searchSubtree(index2)\n",
    "    ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "    return ind1, ind2\n",
    "\n",
    "def traverse_tree(stack, res, parent, idx):\n",
    "    while res != 0:\n",
    "        res -= 1\n",
    "        idx += 1\n",
    "        stack.append((parent[idx], [], idx))\n",
    "        res += parent[idx].arity\n",
    "    # print(f\"stack: {stack}\")\n",
    "    return stack, res, idx\n",
    "\n",
    "def cx_one_point(ind1, ind2):\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    # To track the trees\n",
    "    stack1 = []\n",
    "    stack2 = []\n",
    "    # Store the common region\n",
    "    region1 = []\n",
    "    region2 = []\n",
    "\n",
    "    # Start traversing the trees\n",
    "    while idx1 < len(ind1) and idx2 < len(ind2):\n",
    "        # Push the nodes to the stack\n",
    "        stack1.append((ind1[idx1], [], idx1))\n",
    "        stack2.append((ind2[idx2], [], idx2))\n",
    "\n",
    "        # Not the same region\n",
    "        if stack1[-1][0].arity != stack2[-1][0].arity:\n",
    "            res1 = stack1[-1][0].arity\n",
    "            res2 = stack2[-1][0].arity\n",
    "            stack1, res1, idx1 = traverse_tree(stack1, res1, ind1, idx1)\n",
    "            stack2, res2, idx2 = traverse_tree(stack2, res2, ind2, idx2)\n",
    "        else:\n",
    "            region1.append([ind1[idx1], idx1])\n",
    "            region2.append([ind2[idx2], idx2])\n",
    "\n",
    "        idx1 += 1\n",
    "        idx2 += 1\n",
    "\n",
    "    # for pri, idx in region1:\n",
    "    #     print(f\"{idx}: {pri.name}\")\n",
    "\n",
    "    # Select crossover point\n",
    "    if len(region1) > 0:\n",
    "        point = random.randint(0, len(region1) - 1)\n",
    "        # print(f\"crossover point: {point}\")\n",
    "        # print(f\"crossover point for trees: {region1[point]}, {region2[point]}\")\n",
    "\n",
    "    # Swap subtrees\n",
    "    if len(region1) > 0:\n",
    "        slice1 = ind1.searchSubtree(region1[point][1])\n",
    "        slice2 = ind2.searchSubtree(region2[point][1])\n",
    "        ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    def __init__(self, embeddings, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset):\n",
    "        self.embeddings = embeddings\n",
    "        self.dim = dimension\n",
    "        self.pop_size = population_size\n",
    "        self.population = None\n",
    "        self.cx_method = crossover_method\n",
    "        self.cx_pb = cross_prob\n",
    "        self.mut_pb = mut_prob\n",
    "        self.num_gen = num_generations\n",
    "        self.inputword = dataset[0].str.split().apply(lambda x: x[:5])\n",
    "        self.realword = dataset[0].str.split().str.get(5)\n",
    "        self.eval_count = 0\n",
    "\n",
    "    def register(self):\n",
    "        # Function set\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5)\n",
    "        self.pset.addPrimitive(np.add, 2)\n",
    "        self.pset.addPrimitive(np.subtract, 2)\n",
    "        self.pset.addPrimitive(np.multiply, 2)\n",
    "        self.pset.addPrimitive(protected_div, 2)\n",
    "        self.pset.addPrimitive(protected_sqrt, 1)\n",
    "        self.pset.addPrimitive(np.square, 1)\n",
    "        # Terminal set\n",
    "        count = 0\n",
    "        self.pset.renameArguments(ARG0=\"a\", ARG1=\"b\", ARG2=\"c\", ARG3=\"d\", ARG4=\"e\")\n",
    "        # for line in self.inputword:\n",
    "            # for word in line:\n",
    "                # if count < 5:\n",
    "                    # print(f\"conut: {count}\")\n",
    "                    # print(f\"embedding: {embeddings[word]}, {type(embeddings[word])}\")\n",
    "                    # count += 1\n",
    "                # self.pset.addTerminal(word)\n",
    "\n",
    "        # Initialize the individual\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1,))\n",
    "        creator.create(\n",
    "            \"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax, pset=self.pset\n",
    "        )\n",
    "\n",
    "        # Initialize the toolbox\n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=1, max_=5)\n",
    "        self.toolbox.register(\n",
    "            \"individual\", tools.initIterate, creator.Individual, self.toolbox.expr\n",
    "        )\n",
    "        self.toolbox.register(\n",
    "            \"population\",\n",
    "            tools.initRepeat,\n",
    "            list,\n",
    "            self.toolbox.individual,\n",
    "            n=self.pop_size,\n",
    "        )\n",
    "\n",
    "        # Register the operators\n",
    "        # self.toolbox.register(\"select_candidate\", tools.selRandom, tournsize=3)\n",
    "        self.toolbox.register(\"crossover\", self.crossover)\n",
    "        self.toolbox.register(\"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset)\n",
    "        self.toolbox.register(\"mutate\", gp.staticLimit(operator.attrgetter(\"height\"), max_value=5))\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "\n",
    "        # Register the record for analyzing\n",
    "        self.stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "        self.stats.register(\"avg\", np.mean)\n",
    "        self.stats.register(\"std\", np.std)\n",
    "        self.stats.register(\"min\", np.min)\n",
    "        self.stats.register(\"max\", np.max)\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        data = np.where(np.isinf(data), np.finfo(np.float32).max, data)\n",
    "        data = np.nan_to_num(data, nan=0.0)\n",
    "        return data\n",
    "\n",
    "    def evaluate(self, individual, input_word):\n",
    "        \"\"\"Evalute the fitness of an individual\"\"\"\n",
    "        # print(f\"individual種類:{type(individual)}\")\n",
    "        func = gp.compile(individual, self.pset)\n",
    "        total_similarity = 0.0\n",
    "        for data_index in range(len(input_word)):\n",
    "            words = self.inputword.iloc[data_index]\n",
    "            in_vectors = [self.embeddings[word] for word in words]\n",
    "            a, b, c, d, e = in_vectors[:5]\n",
    "\n",
    "            y = self.realword.iloc[data_index]\n",
    "            out_vector = self.embeddings[y]\n",
    "\n",
    "            predict = self.clean_data(func(a, b, c, d, e))\n",
    "            similarity = cosine_similarity([predict], [out_vector])[0][0]\n",
    "            total_similarity += similarity\n",
    "\n",
    "        fitness = total_similarity / len(self.inputword)\n",
    "        ftiness = self.clean_data(fitness)\n",
    "        self.eval_count += 1\n",
    "        return (fitness,)\n",
    "\n",
    "    def crossover(self, ind1, ind2):\n",
    "        if random.uniform(0, 1) < self.cx_pb:\n",
    "            if self.cx_method == CX_RANDOM:\n",
    "                choice = random.randint(1, 4)\n",
    "            if choice == CX_SIMPLE or self.cx_method == CX_SIMPLE:\n",
    "                ind1, ind2 = cx_simple(parent1, parent2)\n",
    "            elif choice == CX_UNIFORM or self.cx_method == CX_UNIFORM:\n",
    "                ind1, ind2 = cx_uniform(parent1, parent2)\n",
    "            elif choice == CX_ONEPOINT or self.cx_method == CX_FAIR:\n",
    "                ind1, ind2 = cx_fair(parent1, parent2)\n",
    "            else:  # self.cx_method == 4:\n",
    "                ind1, ind2 = cx_one(parent1, parent2)\n",
    "\n",
    "        fitness_ind1 = self.toolbox.evaluate(ind1, self.realword)\n",
    "        # ?:\n",
    "        # if self.cx_method == 2:\n",
    "        #     parents.remove(b)\n",
    "        #     return parents\n",
    "        fitness_ind2 = self.toolbox.evaluate(ind2, self.realword)\n",
    "        if fitness_ind1 <= fitness_ind2:\n",
    "            return ind1\n",
    "        else:\n",
    "            return ind2\n",
    "\n",
    "    def mutate(self, offspring):\n",
    "        if random.uniform(0, 1) < self.mut_pb:\n",
    "            self.toolbox.mutate(child[0])\n",
    "            del child[0].fitness.values\n",
    "        return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of archive (forest size)\n",
    "num_archive = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the 3 types of GP trees, 1/3 for each embedding\n",
    "# word2vec_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset)\n",
    "# word2vec_setup.register()\n",
    "# glove_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "# glove_setup.register()\n",
    "# fasttext_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "# fasttext_setup.register()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset)\n",
    "tree.register()\n",
    "# print(self.pop_size)\n",
    "tree.pop = tree.toolbox.population(n=tree.pop_size)\n",
    "# for ind in tree.pop:\n",
    "#     print(str(ind))\n",
    "# Evaluate the entire population\n",
    "# fitnesses = map(tree.toolbox.evaluate, tree.pop)\n",
    "# for ind, fit in zip(tree.pop, fitnesses):\n",
    "#     ind.fitness.values = fit\n",
    "print(f\"tree.pop type: {type(tree.pop)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record all individuals\n",
    "population_history = []\n",
    "# Initialize the population and record trees for each individuals\n",
    "population = []\n",
    "for i in range(s):\n",
    "    trees = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, dataset)\n",
    "    trees.register()\n",
    "    trees.population = trees.toolbox.population(n=m)\n",
    "    population.append(trees)\n",
    "    population_history.extend(tree for tree in population[i].population)\n",
    "# for i in range(s):\n",
    "#     if i % 3 == 0:\n",
    "#         population.append([WORD2VEC] +word2vec_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n",
    "#     elif i % 3 == 1:\n",
    "#         population.append([GLOVE] + glove_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n",
    "#     else:  # i % 3 == 2\n",
    "#         population.append([FASTTEXT] + fasttext_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(population[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(population[0].population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len((population[0].population)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = []\n",
    "test2.extend(tree for tree in population[0].population)\n",
    "len(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_test1 = copy.deepcopy((population[0].population)[0])\n",
    "parent_test2 = copy.deepcopy((population[3].population)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_test2.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(parent_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring = []\n",
    "for i in range(1):\n",
    "    if random.uniform(0, 1) < population[i].cx_pb:\n",
    "        parent_num = random.randint(0, s - 1)\n",
    "        tree_num = random.randint(0, m - 1)\n",
    "        parent1 = copy.deepcopy((population[i].population)[tree_num])\n",
    "        parent2 = copy.deepcopy((population[parent_num].population)[tree_num])\n",
    "        offspring = population[i].toolbox.crossover(parent1, parent2)\n",
    "        while not (offspring in population_history):\n",
    "            offspring = population[i].toolbox.crossover(parent1, parent2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(offspring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    if random.uniform(0, 1) < population[i].mut_pb:\n",
    "        population[i].toolbox.mutate(offspring)\n",
    "        del offspring.fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each generation (n_gen generations)\n",
    "    # For each individual (DT) (s individuals)\n",
    "        # For each GP tree (m trees)\n",
    "            # Randomly initialize the tree\n",
    "\n",
    "        # For each individual (DT)\n",
    "            # Randomly select another individual\n",
    "            # Randomly select a tree from each individual\n",
    "            # Crossover the two trees\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "            # Mutation\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "        # Evaluate the fitness of each individual: Fivefold cross-validation\n",
    "        # Traing dataset: divided into five folds\n",
    "        # For four folds: train the a DT model\n",
    "        # For the remaining fold: test the model\n",
    "        # Concatenate these five loss values into a fitness vector\n",
    "\n",
    "        # Select the best individual: Automatic lexicase selection\n",
    "        # Fitness vector L: i-th individual's fitness vector\n",
    "        # While the number of selected individuals == s\n",
    "            # Randomly choose an index j\n",
    "                # j = np.random.randint(m)\n",
    "            # Threshold theta = min(L_i[j]) + median(abs(L_i[j] + median(L_k[j]))\n",
    "                # Calculate the median absolute deviation (MAD)\n",
    "                    # fitness_j = [L[j] for L in individauls]\n",
    "                    # median_j = np.median(fitness_j)\n",
    "                    # mad_j = np.median([abs(f - median_j) for f in fitness_j])\n",
    "                # Calculate the threshold theta\n",
    "                    # theta_j = np.min(fitness_j) + mad_j\n",
    "            # For each individual\n",
    "                # j-th fitness element > theta -> preserve the individual\n",
    "                # Number of selected individuals\n",
    "                # Case 1: > 1, then repeat the filtering process\n",
    "                # Case 2: == 1, then select the individual\n",
    "                # Case 3: == 0, then randomly select an individual\n",
    "\n",
    "        # Archive the best individual\n",
    "        # For each selected individual\n",
    "            # If the number of selected individuals < remain num_archive\n",
    "                # Add to the archive\n",
    "            # Else, replace the worst individual in the archive with the best individual\n",
    "                # Find the minimum fitness value; fitness value = average of the fitness vector\n",
    "    # Return the archive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
