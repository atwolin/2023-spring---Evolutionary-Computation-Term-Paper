{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "import pprint\n",
    "import numpy as np\n",
    "# import gp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import deap.gp as gp\n",
    "from deap import creator, base, tools, algorithms\n",
    "from deap.gp import cxOnePoint as cx_simple\n",
    "from deap.gp import PrimitiveSet\n",
    "from data import load_model, get_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "WORD2VEC = \"word2vec\"\n",
    "GLOVE = \"glove\"\n",
    "FASTTEXT = \"fasttext\"\n",
    "CX_RANDOM = 0\n",
    "CX_SIMPLE = 1\n",
    "CX_UNIFORM = 2\n",
    "CX_FAIR = 3\n",
    "CX_ONEPOINT = 4\n",
    "\n",
    "population_size = s = 50\n",
    "m = 5\n",
    "dim = 10\n",
    "crossover_method = CX_RANDOM\n",
    "cross_prob = 0.5\n",
    "mut_prob = 0.1\n",
    "num_generations = 30\n",
    "embedding = WORD2VEC\n",
    "\n",
    "word2vec_model, glove_model, fastText_model = load_model(dim)\n",
    "data, embeddings = get_embeddings(WORD2VEC, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2669"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.020154  ,  0.6807334 , -1.5517452 , -7.0284715 , -0.84560966,\n",
       "       -2.781589  , -0.30933514,  2.6115234 , -2.6106572 , -1.5751432 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[data[0][0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic operators\n",
    "def protected_div(x, y):\n",
    "    mask = y == 0\n",
    "    safe_y = np.where(mask, 1, y)\n",
    "    return np.where(mask, 1, x / safe_y)\n",
    "\n",
    "\n",
    "def protected_sqrt(x):\n",
    "    sign = np.sign(x)\n",
    "    x = np.abs(x)\n",
    "    return np.sqrt(x) * sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crossover method\n",
    "def subtree_height(tree, index):\n",
    "        \"\"\"\n",
    "        Calculate the height of the subtree starting at the given index.\n",
    "        \"\"\"\n",
    "        def height(node_index):\n",
    "            node = tree[node_index]\n",
    "            if node.arity == 0:  # Leaf node\n",
    "                return 1\n",
    "            else:\n",
    "                return 1 + max(\n",
    "                    height(child_index)\n",
    "                    for child_index in range(\n",
    "                        node_index + 1, node_index + 1 + node.arity\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return height(index)\n",
    "\n",
    "def searchSubtree_idx(tree, begin):\n",
    "        end = begin + 1\n",
    "        total = tree[begin].arity\n",
    "        while total > 0:\n",
    "            total += tree[end].arity - 1\n",
    "            end += 1\n",
    "        return begin, end\n",
    "\n",
    "def cx_uniform(ind1, ind2):\n",
    "        # No crossover on single node tree\n",
    "        if (len(ind1) < 2 or len(ind2) < 2):\n",
    "            return ind1, ind2\n",
    "\n",
    "        child = type(ind1)([])\n",
    "        parents = [ind1, ind2]\n",
    "        flag0, flag1 = 0, 0\n",
    "        left_0 = parents[0].searchSubtree(1)\n",
    "        left_1 = parents[1].searchSubtree(1)\n",
    "        b0, e0 = searchSubtree_idx(parents[0], 1)\n",
    "        b1, e1 = searchSubtree_idx(parents[1], 1)\n",
    "\n",
    "        if e0 + 1 < len(parents[0]):\n",
    "            right_0 = parents[0].searchSubtree(e0 + 1)\n",
    "            flag0 = 1\n",
    "        if e1 + 1 < len(parents[1]):\n",
    "            right_1 = parents[1].searchSubtree(e1 + 1)\n",
    "            flag1 = 1\n",
    "        left = [left_0, left_1]\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            right = [right_0, right_1]\n",
    "            r_arity = 0\n",
    "            if parents[0][e0 + 1].arity == parents[1][e1 + 1].arity:\n",
    "                r_arity = 1\n",
    "        r = random.randint(0, 1)  # root\n",
    "        m = 1 - r\n",
    "        if len(parents[r]) < len(parents[m]):\n",
    "            # root = parents[r].root\n",
    "            if flag1 == 0 or flag0 == 0:\n",
    "                return parents[r], parents[m]\n",
    "            parents[m][0] = parents[r].root\n",
    "            m = r\n",
    "        if flag0 == 1 and flag1 == 1:\n",
    "            r1 = random.randint(0, 1)  # 左邊\n",
    "            if parents[r][1] == parents[r1][1]:\n",
    "                parents[r][left[r]] = parents[r1][left[r1]]\n",
    "            if r_arity == 1:\n",
    "                r2 = random.randint(0, 1)\n",
    "                parents[r][right[r]] = parents[r2][right[r2]]\n",
    "        else:\n",
    "            # print(\"只有一個子點\")\n",
    "            r1 = random.randint(0, 1)\n",
    "            parents[r][left[r1]] = parents[r1][left[r1]]\n",
    "        return parents[r], parents[r]\n",
    "\n",
    "def cx_fair(ind1, ind2):\n",
    "    \"\"\"Size fair crossover for two trees.\n",
    "    :param ind1: First tree participating in the crossover.\n",
    "    :param ind2: Second tree participating in the crossover.\n",
    "    :returns: A tuple of two trees.\n",
    "    \"\"\"\n",
    "    # No crossover on single node tree\n",
    "    if len(ind1) < 2 or len(ind2) < 2:\n",
    "        return ind1, ind2\n",
    "\n",
    "    # List all available primitive types in each individual\n",
    "    types1 = gp.defaultdict(list)\n",
    "    types2 = gp.defaultdict(list)\n",
    "    if ind1.root.ret == gp.__type__:\n",
    "        # Not STGP optimization\n",
    "        types1[gp.__type__] = list(range(1, len(ind1)))\n",
    "        types2[gp.__type__] = list(range(1, len(ind2)))\n",
    "        common_types = [gp.__type__]\n",
    "    else:\n",
    "        for idx, node in enumerate(ind1[1:], 1):\n",
    "            types1[node.ret].append(idx)\n",
    "        for idx, node in enumerate(ind2[1:], 1):\n",
    "            types2[node.ret].append(idx)\n",
    "        common_types = set(types1.keys()).intersection(set(types2.keys()))\n",
    "\n",
    "    if len(common_types) > 0:\n",
    "        type_ = random.choice(list(common_types))\n",
    "\n",
    "    index1 = random.choice(types1[type_])\n",
    "    height1 = subtree_height(ind1, index1)\n",
    "    # height = ind1.height\n",
    "\n",
    "    while True:\n",
    "        index2 = random.choice(types2[type_])\n",
    "        height2 = subtree_height(ind2, index2)\n",
    "        if height2 <= height1:\n",
    "            # print(f\"height1: {height1}, height2: {height2}\")\n",
    "            break\n",
    "    slice1 = ind1.searchSubtree(index1)\n",
    "    slice2 = ind2.searchSubtree(index2)\n",
    "    ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "    return ind1, ind2\n",
    "\n",
    "def traverse_tree(stack, res, parent, idx):\n",
    "    while res != 0:\n",
    "        res -= 1\n",
    "        idx += 1\n",
    "        stack.append((parent[idx], [], idx))\n",
    "        res += parent[idx].arity\n",
    "    # print(f\"stack: {stack}\")\n",
    "    return stack, res, idx\n",
    "\n",
    "def cx_one_point(ind1, ind2):\n",
    "    idx1 = 0\n",
    "    idx2 = 0\n",
    "    # To track the trees\n",
    "    stack1 = []\n",
    "    stack2 = []\n",
    "    # Store the common region\n",
    "    region1 = []\n",
    "    region2 = []\n",
    "\n",
    "    # Start traversing the trees\n",
    "    while idx1 < len(ind1) and idx2 < len(ind2):\n",
    "        # Push the nodes to the stack\n",
    "        stack1.append((ind1[idx1], [], idx1))\n",
    "        stack2.append((ind2[idx2], [], idx2))\n",
    "\n",
    "        # Not the same region\n",
    "        if stack1[-1][0].arity != stack2[-1][0].arity:\n",
    "            res1 = stack1[-1][0].arity\n",
    "            res2 = stack2[-1][0].arity\n",
    "            stack1, res1, idx1 = traverse_tree(stack1, res1, ind1, idx1)\n",
    "            stack2, res2, idx2 = traverse_tree(stack2, res2, ind2, idx2)\n",
    "        else:\n",
    "            region1.append([ind1[idx1], idx1])\n",
    "            region2.append([ind2[idx2], idx2])\n",
    "\n",
    "        idx1 += 1\n",
    "        idx2 += 1\n",
    "\n",
    "    # for pri, idx in region1:\n",
    "    #     print(f\"{idx}: {pri.name}\")\n",
    "\n",
    "    # Select crossover point\n",
    "    if len(region1) > 0:\n",
    "        point = random.randint(0, len(region1) - 1)\n",
    "        # print(f\"crossover point: {point}\")\n",
    "        # print(f\"crossover point for trees: {region1[point]}, {region2[point]}\")\n",
    "\n",
    "    # Swap subtrees\n",
    "    if len(region1) > 0:\n",
    "        slice1 = ind1.searchSubtree(region1[point][1])\n",
    "        slice2 = ind2.searchSubtree(region2[point][1])\n",
    "        ind1[slice1], ind2[slice2] = ind2[slice2], ind1[slice1]\n",
    "\n",
    "    return ind1, ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GP():\n",
    "    def __init__(self, embedding, dimension, population_size, crossover_method, cross_prob, mut_prob, num_generations, data):\n",
    "        self.embedding = embeddings\n",
    "        self.dim = dimension\n",
    "        self.pop_size = population_size\n",
    "        self.cx_method = crossover_method\n",
    "        self.cx_prob = cross_prob\n",
    "        self.mut_prob = mut_prob\n",
    "        self.num_gen = num_generations\n",
    "        self.data = data\n",
    "        self.eval_count = 0\n",
    "\n",
    "    def register(self):\n",
    "        # Function set\n",
    "        self.pset = gp.PrimitiveSet(\"MAIN\", 5)\n",
    "        self.pset.addPrimitive(np.add, 2)\n",
    "        self.pset.addPrimitive(np.subtract, 2)\n",
    "        self.pset.addPrimitive(np.multiply, 2)\n",
    "        self.pset.addPrimitive(protected_div, 2)\n",
    "        self.pset.addPrimitive(protected_sqrt, 1)\n",
    "        self.pset.addPrimitive(np.square, 1)\n",
    "        # Terminal set\n",
    "        count = 0\n",
    "        self.pset.renameArguments(ARG0=\"w0\", ARG1=\"w1\", ARG2=\"w2\", ARG3=\"w3\", ARG4=\"w4\")\n",
    "        for line in data:\n",
    "            for word in line[0]:\n",
    "                # if count < 5:\n",
    "                #     print(f\"conut: {count}\")\n",
    "                #     print(f\"embedding: {embeddings[word]}, {type(embeddings[word])}\")\n",
    "                #     count += 1\n",
    "                self.pset.addTerminal(embeddings[word].all())\n",
    "\n",
    "        # Initialize the individual\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1,))\n",
    "        creator.create(\n",
    "            \"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMax, pset=self.pset\n",
    "        )\n",
    "\n",
    "        # Initialize the toolbox\n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.toolbox.register(\"expr\", gp.genHalfAndHalf, pset=self.pset, min_=1, max_=5)\n",
    "        self.toolbox.register(\n",
    "            \"individual\", tools.initIterate, creator.Individual, self.toolbox.expr\n",
    "        )\n",
    "        self.toolbox.register(\n",
    "            \"population\",\n",
    "            tools.initRepeat,\n",
    "            list,\n",
    "            self.toolbox.individual,\n",
    "            n=self.pop_size,\n",
    "        )\n",
    "\n",
    "        # Register the operators\n",
    "        # self.toolbox.register(\"select_candidate\", tools.selRandom, tournsize=3)\n",
    "        self.toolbox.register(\"crossover\", self.crossover)\n",
    "        self.toolbox.register(\"mutate\", gp.mutUniform, expr=self.toolbox.expr, pset=self.pset)\n",
    "        self.toolbox.register(\"mutate\", gp.staticLimit(operator.attrgetter(\"height\"), max_value=5))\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "\n",
    "        # Register the record for analyzing\n",
    "        self.stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "        self.stats.register(\"avg\", np.mean)\n",
    "        self.stats.register(\"std\", np.std)\n",
    "        self.stats.register(\"min\", np.min)\n",
    "        self.stats.register(\"max\", np.max)\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        data = np.where(np.isinf(data), np.finfo(np.float32).max, data)\n",
    "        data = np.nan_to_num(data, nan=0.0)\n",
    "        return data\n",
    "\n",
    "    def evaluate(self, individual, input_word):\n",
    "        \"\"\"Evalute the fitness of an individual\"\"\"\n",
    "        # print(f\"individual種類:{type(individual)}\")\n",
    "        func = gp.compile(individual, self.pset)\n",
    "        total_similarity = 0.0\n",
    "        for data_index in range(len(input_word)):\n",
    "            words = self.inputword.iloc[data_index]\n",
    "            in_vectors = [self.embeddings[word] for word in words]\n",
    "            a, b, c, d, e = in_vectors[:5]\n",
    "\n",
    "            y = self.realword.iloc[data_index]\n",
    "            out_vector = self.embeddings[y]\n",
    "\n",
    "            predict = self.clean_data(func(a, b, c, d, e))\n",
    "            similarity = cosine_similarity([predict], [out_vector])[0][0]\n",
    "            total_similarity += similarity\n",
    "\n",
    "        fitness = total_similarity / len(self.inputword)\n",
    "        ftiness = self.clean_data(fitness)\n",
    "        self.eval_count += 1\n",
    "        return (fitness,)\n",
    "\n",
    "    def crossover(self, ind1, ind2):\n",
    "        if random.uniform(0, 1) < self.cx_prob:\n",
    "            if self.cx_method == CX_RANDOM:\n",
    "                choice = random.randint(1, 4)\n",
    "            if choice == CX_SIMPLE or self.cx_method == CX_SIMPLE:\n",
    "                ind1, ind2 = cx_simple(parent1, parent2)\n",
    "            elif choice == CX_UNIFORM or self.cx_method == CX_UNIFORM:\n",
    "                ind1, ind2 = cx_uniform(parent1, parent2)\n",
    "            elif choice == CX_ONEPOINT or self.cx_method == CX_FAIR:\n",
    "                ind1, ind2 = self.toolbox.cx_fair(parent1, parent2)\n",
    "            else:  # self.cx_method == 4:\n",
    "                ind1, ind2 = self.toolbox.cx_one(parent1, parent2)\n",
    "\n",
    "        fitness_ind1 = self.toolbox.evaluate(ind1)\n",
    "        # ?:\n",
    "        # if self.cx_method == 2:\n",
    "        #     parents.remove(b)\n",
    "        #     return parents\n",
    "        fitness_ind2 = self.toolbox.evaluate(ind2)\n",
    "        if fitness_ind1 <= fitness_ind2:\n",
    "            return ind1\n",
    "        else:\n",
    "            return ind2\n",
    "\n",
    "    def mutate(self, offspring):\n",
    "        if random.uniform(0, 1) < self.mut_prob:\n",
    "            self.toolbox.mutate(child[0])\n",
    "            del child[0].fitness.values\n",
    "        return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record all individuals\n",
    "population_history = []\n",
    "# Number of archive (forest size)\n",
    "num_archive = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlplab/atwolin/EC/yes/envs/env_p/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/nlplab/atwolin/EC/yes/envs/env_p/lib/python3.9/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# Set up GP tree\n",
    "word2vec_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, data)\n",
    "word2vec_setup.register()\n",
    "\n",
    "# Set up the 3 types of GP trees, 1/3 for each embedding\n",
    "# word2vec_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations, data)\n",
    "# word2vec_setup.register()\n",
    "# glove_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "# glove_setup.register()\n",
    "# fasttext_setup = GP(embeddings, dim, population_size, crossover_method, cross_prob, mut_prob, num_generations)\n",
    "# fasttext_setup.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = word2vec_setup.toolbox.population(n=m)\n",
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deap.creator.Individual"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Pri(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<deap.gp.Primitive at 0x7fdc25b03d60>,\n",
       "  <deap.gp.Terminal at 0x7fdbcb973340>,\n",
       "  <deap.gp.Terminal at 0x7fdbcad29b40>],\n",
       " [<deap.gp.Primitive at 0x7fdc25b034f0>,\n",
       "  <deap.gp.Primitive at 0x7fdc25b03b30>,\n",
       "  <deap.gp.Primitive at 0x7fdc25b034f0>,\n",
       "  <deap.gp.Terminal at 0x7fdbcacb3bc0>,\n",
       "  <deap.gp.Terminal at 0x7fdbcb071a00>,\n",
       "  <deap.gp.Primitive at 0x7fdc25b03d60>,\n",
       "  <deap.gp.Terminal at 0x7fdbcae74e80>,\n",
       "  <deap.gp.Terminal at 0x7fdbbba7c2c0>,\n",
       "  <deap.gp.Primitive at 0x7fdc25b03180>,\n",
       "  <deap.gp.Primitive at 0x7fdc25b03b80>,\n",
       "  <deap.gp.Terminal at 0x7fdc3f7c0440>,\n",
       "  <deap.gp.Terminal at 0x7fdc3f288d00>],\n",
       " [<deap.gp.Primitive at 0x7fdc25b03d60>,\n",
       "  <deap.gp.Terminal at 0x7fdbbc093080>,\n",
       "  <deap.gp.Terminal at 0x7fdbca692d00>],\n",
       " [<deap.gp.Primitive at 0x7fdc25b03b30>,\n",
       "  <deap.gp.Terminal at 0x7fdbbaefda00>,\n",
       "  <deap.gp.Terminal at 0x7fdbcba44500>],\n",
       " [<deap.gp.Primitive at 0x7fdc25b03d60>,\n",
       "  <deap.gp.Terminal at 0x7fdc3698aa40>,\n",
       "  <deap.gp.Terminal at 0x7fdbba6b4480>]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test3 = []\n",
    "# test3.append([WORD2VEC] + word2vec_setup.toolbox.population(n=m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the population and record trees for each individuals\n",
    "population = []\n",
    "for i in range(s):\n",
    "    population.append(word2vec_setup.toolbox.population(n=m))\n",
    "    population_history.extend(tree for tree in population[i])\n",
    "# for i in range(s):\n",
    "#     if i % 3 == 0:\n",
    "#         population.append([WORD2VEC] +word2vec_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n",
    "#     elif i % 3 == 1:\n",
    "#         population.append([GLOVE] + glove_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n",
    "#     else:  # i % 3 == 2\n",
    "#         population.append([FASTTEXT] + fasttext_setup.toolbox.population(n=m))\n",
    "#         population_history.extend(tree for tree in population[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = []\n",
    "test2.extend(tree for tree in population[0])\n",
    "len(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_test1 = population[0][0].copy()\n",
    "parent_test2 = population[3][3].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[<deap.gp.Primitive object at 0x7fdc25b03b30>, <deap.gp.Primitive object at 0x7fdc25b03180>, <deap.gp.Primitive object at 0x7fdc25b03040>, <deap.gp.Terminal object at 0x7fdbb9adcd00>, <deap.gp.Primitive object at 0x7fdc25b03180>, <deap.gp.Primitive object at 0x7fdc25b03040>, <deap.gp.Terminal object at 0x7fdc257d7b40>]'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parent_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m parent1 \u001b[38;5;241m=\u001b[39m population[i][tree_num]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      5\u001b[0m parent2 \u001b[38;5;241m=\u001b[39m population[parent_num][tree_num]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m----> 6\u001b[0m offspring \u001b[38;5;241m=\u001b[39m \u001b[43mword2vec_setup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoolbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossover\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (offspring \u001b[38;5;129;01min\u001b[39;00m population_history):\n\u001b[1;32m      8\u001b[0m     offspring \u001b[38;5;241m=\u001b[39m word2vec_setup\u001b[38;5;241m.\u001b[39mtoolbox\u001b[38;5;241m.\u001b[39mcrossover(parent1, parent2)\n",
      "Cell \u001b[0;32mIn[23], line 99\u001b[0m, in \u001b[0;36mGP.crossover\u001b[0;34m(self, ind1, ind2)\u001b[0m\n\u001b[1;32m     97\u001b[0m     choice \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m CX_SIMPLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcx_method \u001b[38;5;241m==\u001b[39m CX_SIMPLE:\n\u001b[0;32m---> 99\u001b[0m     ind1, ind2 \u001b[38;5;241m=\u001b[39m \u001b[43mcx_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m CX_UNIFORM \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcx_method \u001b[38;5;241m==\u001b[39m CX_UNIFORM:\n\u001b[1;32m    101\u001b[0m     ind1, ind2 \u001b[38;5;241m=\u001b[39m cx_uniform(parent1, parent2)\n",
      "File \u001b[0;32m~/EC/yes/envs/env_p/lib/python3.9/site-packages/deap/gp.py:674\u001b[0m, in \u001b[0;36mcxOnePoint\u001b[0;34m(ind1, ind2)\u001b[0m\n\u001b[1;32m    672\u001b[0m types1 \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m    673\u001b[0m types2 \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mind1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[38;5;241m.\u001b[39mret \u001b[38;5;241m==\u001b[39m __type__:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# Not STGP optimization\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     types1[__type__] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ind1)))\n\u001b[1;32m    677\u001b[0m     types2[__type__] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ind2)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'root'"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    parent_num = random.randint(0, s - 1)\n",
    "    tree_num = random.randint(0, m - 1)\n",
    "    parent1 = population[i][tree_num].copy()\n",
    "    parent2 = population[parent_num][tree_num].copy()\n",
    "    offspring = word2vec_setup.toolbox.crossover(parent1, parent2)\n",
    "    while not (offspring in population_history):\n",
    "        offspring = word2vec_setup.toolbox.crossover(parent1, parent2)\n",
    "    pprint(offspring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each generation (n_gen generations)\n",
    "    # For each individual (DT) (s individuals)\n",
    "        # For each GP tree (m trees)\n",
    "            # Randomly initialize the tree\n",
    "\n",
    "        # For each individual (DT)\n",
    "            # Randomly select another individual\n",
    "            # Randomly select a tree from each individual\n",
    "            # Crossover the two trees\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "            # Mutation\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "        # Evaluate the fitness of each individual: Fivefold cross-validation\n",
    "        # Traing dataset: divided into five folds\n",
    "        # For four folds: train the a DT model\n",
    "        # For the remaining fold: test the model\n",
    "        # Concatenate these five loss values into a fitness vector\n",
    "\n",
    "        # Select the best individual: Automatic lexicase selection\n",
    "        # Fitness vector L: i-th individual's fitness vector\n",
    "        # While the number of selected individuals == s\n",
    "            # Randomly choose an index j\n",
    "                # j = np.random.randint(m)\n",
    "            # Threshold theta = min(L_i[j]) + median(abs(L_i[j] + median(L_k[j]))\n",
    "                # Calculate the median absolute deviation (MAD)\n",
    "                    # fitness_j = [L[j] for L in individauls]\n",
    "                    # median_j = np.median(fitness_j)\n",
    "                    # mad_j = np.median([abs(f - median_j) for f in fitness_j])\n",
    "                # Calculate the threshold theta\n",
    "                    # theta_j = np.min(fitness_j) + mad_j\n",
    "            # For each individual\n",
    "                # j-th fitness element > theta -> preserve the individual\n",
    "                # Number of selected individuals\n",
    "                # Case 1: > 1, then repeat the filtering process\n",
    "                # Case 2: == 1, then select the individual\n",
    "                # Case 3: == 0, then randomly select an individual\n",
    "\n",
    "        # Archive the best individual\n",
    "        # For each selected individual\n",
    "            # If the number of selected individuals < remain num_archive\n",
    "                # Add to the archive\n",
    "            # Else, replace the worst individual in the archive with the best individual\n",
    "                # Find the minimum fitness value; fitness value = average of the fitness vector\n",
    "    # Return the archive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
