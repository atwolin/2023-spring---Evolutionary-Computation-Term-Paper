{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CX_RANDOM = 5\n",
    "pop_size = 100\n",
    "dim = 10\n",
    "cx_method = CX_RANDOM\n",
    "mut_pb = 0.1\n",
    "n_gen = 30\n",
    "data, embeddings = gp.get_embeddings(\"word2vec\", 10, 1)\n",
    "setup = gp.GP(pop_size, dim, cx_method, mut_pb, n_gen, data, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record all individuals\n",
    "# num_archive\n",
    "\n",
    "# Randomly initialize the population\n",
    "\n",
    "# For each generation (n_gen generations)\n",
    "    # For each individual (DT) (s individuals)\n",
    "        # For each GP tree (m trees)\n",
    "            # Randomly initialize the tree\n",
    "\n",
    "        # For each individual (DT)\n",
    "            # Randomly select another individual\n",
    "            # Randomly select a tree from each individual\n",
    "            # Crossover the two trees\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "            # Mutation\n",
    "            # End if the offspring is not repeated\n",
    "\n",
    "        # Evaluate the fitness of each individual: Fivefold cross-validation\n",
    "        # Traing dataset: divided into five folds\n",
    "        # For four folds: train the a DT model\n",
    "        # For the remaining fold: test the model\n",
    "        # Concatenate these five loss values into a fitness vector\n",
    "\n",
    "        # Select the best individual: Automatic lexicase selection\n",
    "        # Fitness vector L: i-th individual's fitness vector\n",
    "        # While the number of selected individuals == s\n",
    "            # Randomly choose an index j\n",
    "                # j = np.random.randint(m)\n",
    "            # Threshold theta = min(L_i[j]) + median(abs(L_i[j] + median(L_k[j]))\n",
    "                # Calculate the median absolute deviation (MAD)\n",
    "                    # fitness_j = [L[j] for L in individauls]\n",
    "                    # median_j = np.median(fitness_j)\n",
    "                    # mad_j = np.median([abs(f - median_j) for f in fitness_j])\n",
    "                # Calculate the threshold theta\n",
    "                    # theta_j = np.min(fitness_j) + mad_j\n",
    "            # For each individual\n",
    "                # j-th fitness element > theta -> preserve the individual\n",
    "                # Number of selected individuals\n",
    "                # Case 1: > 1, then repeat the filtering process\n",
    "                # Case 2: == 1, then select the individual\n",
    "                # Case 3: == 0, then randomly select an individual\n",
    "\n",
    "        # Archive the best individual\n",
    "        # For each selected individual\n",
    "            # If the number of selected individuals < remain num_archive\n",
    "                # Add to the archive\n",
    "            # Else, replace the worst individual in the archive with the best individual\n",
    "                # Find the minimum fitness value; fitness value = average of the fitness vector\n",
    "    # Return the archive"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
